{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stopwords :\n",
    "\n",
    "a, an , the, etc., they may be helpful for human beings but for analysis they are just filller words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = 'This is an example sentence and it will help us to see about stopwords because stopwords are need to be removed as they are just filler words, they donot have their own meaning!!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'but', 'me', 'ain', 'out', 'him', 've', \"mustn't\", 'further', 'will', \"isn't\", 'hers', \"won't\", 'he', 'has', 'when', \"couldn't\", 'if', 'no', 'we', 'won', \"should've\", 'yours', 'shouldn', 'of', 'too', 'didn', 'does', 'as', 'a', 'which', \"you'll\", 'from', 'wasn', 'should', 'ours', 'shan', \"shouldn't\", 'you', 'weren', 'being', 'at', 'such', 'about', 'this', 'your', 'here', 'above', \"aren't\", \"she's\", 'doesn', 'there', 'an', \"wouldn't\", 'yourself', \"needn't\", 'very', 'through', 're', 'do', 's', 't', 'what', 'did', 'don', 'mightn', 'not', 'my', \"you'd\", 'and', 'with', 'that', 'them', 'more', 'been', 'during', 'aren', 'below', 'ma', 'myself', \"mightn't\", 'doing', 'few', 'is', 'were', 'needn', 'can', 'wouldn', 'himself', 'hadn', 'most', 'how', 'themselves', 'haven', 'up', 'into', 'yourselves', \"doesn't\", 'just', 'over', 'ourselves', 'then', 'itself', 'down', \"you're\", 'the', \"haven't\", 'his', 'their', 'on', \"hasn't\", 'because', 'in', 'against', 'between', 'again', 'or', 'she', 'it', 'nor', 'o', 'to', 'off', \"hadn't\", \"you've\", 'where', \"shan't\", 'same', 'why', 'm', \"wasn't\", 'only', 'd', 'once', 'any', 'after', 'now', 'be', 'who', 'was', 'they', 'by', 'whom', 'have', 'having', 'had', 'am', 'll', 'each', 'those', 'are', 'these', 'hasn', 'under', 'y', \"don't\", 'isn', \"didn't\", \"weren't\", 'own', \"it's\", 'both', 'some', 'her', 'i', 'our', 'for', 'before', 'all', 'theirs', 'other', 'its', 'mustn', 'herself', 'so', 'until', 'than', 'couldn', \"that'll\", 'while'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'example', 'sentence', 'help', 'us', 'see', 'stopwords', 'stopwords', 'need', 'removed', 'filler', 'words', ',', 'donot', 'meaning', '!', '!', '!']\n",
      "['This', 'example', 'sentence', 'help', 'us', 'see', 'stopwords', 'stopwords', 'need', 'removed', 'filler', 'words', ',', 'donot', 'meaning', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(example_sentence)\n",
    "# filtered_sentence = []\n",
    "\n",
    "# for word in words:\n",
    "#     if word not in stop_words:\n",
    "#         filtered_sentence.append(word)\n",
    "        \n",
    "# print(filtered_sentence)\n",
    "\n",
    "# one liner for above for loop\n",
    "filtered_sentence = [w for w in words if not w in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
