{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Bias\n",
    "\n",
    "How much accurate we are?\n",
    "in this chapter we're going to do one last look at some some of the data and our accuracy\n",
    "\n",
    "Let's say we have 75% accurate average. That could be 100% accurate on negative stuff and 50% accurate on positive stuffs so our average is 75. \n",
    "\n",
    "So what we want to know right now is what is the distribution between our accuracy on positive information and our accuracy on negative  nformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random # this we will use to shuffle our dataset, coz for now it is higlhy ordered, first all negative, than positive than neutaral.\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "# this is basically an nltk module but it is actually a wrapper around the sklearn classifier to add its functionilities in nltk\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every single sklearn learn algorithm comes paired with a bunch of parameters you can use. The default parameters are general parameters that are pretty good but it's good to know what the parameters are and how adjusting them will change your success. \n",
    "\n",
    ">So, keep that in mind that despite the success that we get with these parameter whether it's good or bad you can probably improve that success by at least ten percent by correctly choosing and not using the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining algos with a vote\n",
    "from nltk.classify import ClassifierI # this is so we can inherit from the \"nltk classifier\" class\n",
    "from statistics import mode # this is how we are gonna choose who got the most votes, we're just gonna take the mode\n",
    "# The mode of a set of data values is the value that appears most often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    \n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for classifier in self._classifiers:\n",
    "            vote = classifier.classify(features)\n",
    "            votes.append(vote)\n",
    "        \n",
    "        return mode(votes)\n",
    "    \n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for classifier in self._classifiers:\n",
    "            vote = classifier.classify(features)\n",
    "            votes.append(vote)\n",
    "        \n",
    "        choice_votes = votes.count(mode(votes)) # how many occurences of most popular votes in that list\n",
    "        confid = choice_votes / len(votes) # this is give us certainity\n",
    "        \n",
    "        return confid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(documents)\n",
    "# print(documents[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_what we're going to end up having to do is take all of these words though literally take every word in every review and compile them and then basically we do is we'll take that list of words and we'll find the most popular words  used and then we take of those most popular words which one appear in positive text and which ones negative text and then we simply just search for those words and whichever one it has more negative words or more positive words that's how we classify it_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in words:\n",
    "        features[w] = (w in words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # positive data example\n",
    "# train_set = featuresets[:1900]\n",
    "# test_set = featuresets[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative data example\n",
    "train_set = featuresets[100:]\n",
    "test_set = featuresets[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Byes Algorithm\n",
    "posterior = prior occurences * occurences / likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading classifier from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_f = open('naivebyes.pickle', 'rb')\n",
    "classifier = pickle.load(classifier_f)     \n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes algo accuracy:  47.0\n",
      "Most Informative Features\n",
      "               insulting = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "                gripping = True              pos : neg    =     11.7 : 1.0\n",
      "                   sucks = True              neg : pos    =     11.3 : 1.0\n",
      "              astounding = True              pos : neg    =     11.1 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.0 : 1.0\n",
      "                    3000 = True              neg : pos    =     10.7 : 1.0\n",
      "                  hudson = True              neg : pos    =     10.7 : 1.0\n",
      "                  regard = True              pos : neg    =     10.5 : 1.0\n",
      "                    slip = True              pos : neg    =     10.5 : 1.0\n",
      "             outstanding = True              pos : neg    =     10.4 : 1.0\n",
      "          excruciatingly = True              neg : pos    =     10.0 : 1.0\n",
      "              incoherent = True              neg : pos    =     10.0 : 1.0\n",
      "                    sans = True              neg : pos    =     10.0 : 1.0\n",
      "                  elliot = True              pos : neg    =      9.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Original Naive Bayes algo accuracy: ', nltk.classify.accuracy(classifier, test_set) * 100)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB_classifier accuracy:  80.0\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB()) \n",
    "MNB_classifier.train(train_set)\n",
    "print('MNB_classifier accuracy: ', nltk.classify.accuracy(MNB_classifier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNB_classifier = SklearnClassifier(GaussianNB()) \n",
    "# GNB_classifier.train(train_set)\n",
    "# print('GNB_classifier accuracy: ', nltk.classify.accuracy(GNB_classifier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB_classifier accuracy:  83.0\n"
     ]
    }
   ],
   "source": [
    "BNB_classifier = SklearnClassifier(BernoulliNB()) \n",
    "BNB_classifier.train(train_set)\n",
    "print('BNB_classifier accuracy: ', nltk.classify.accuracy(BNB_classifier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy:  82.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression()) \n",
    "LogisticRegression_classifier.train(train_set)\n",
    "print('LogisticRegression_classifier accuracy: ', nltk.classify.accuracy(LogisticRegression_classifier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy:  78.0\n"
     ]
    }
   ],
   "source": [
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier()) \n",
    "SGDClassifier_classifier.train(train_set)\n",
    "print('SGDClassifier_classifier accuracy: ', nltk.classify.accuracy(SGDClassifier_classifier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC_classifier = SklearnClassifier(SVC()) \n",
    "# SVC_classifier.train(train_set)\n",
    "# print('SVC_classifier accuracy: ', nltk.classify.accuracy(SVC_classifier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC_classifier accuracy:  82.0\n"
     ]
    }
   ],
   "source": [
    "NuSVC_classifier = SklearnClassifier(NuSVC()) \n",
    "NuSVC_classifier.train(train_set)\n",
    "print('NuSVC_classifier accuracy: ', nltk.classify.accuracy(NuSVC_classifier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_classifier accuracy:  80.0\n"
     ]
    }
   ],
   "source": [
    "LinearSVC_classifier = SklearnClassifier(LinearSVC()) \n",
    "LinearSVC_classifier.train(train_set)\n",
    "print('LinearSVC_classifier accuracy: ', nltk.classify.accuracy(LinearSVC_classifier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember\n",
    "\n",
    ">These all above algos(classifiers) have got their own parameters, which we can tweak and imrove our accuracy, currently here we have used the default values for each of them.\n",
    ">\n",
    ">If you want to know more about those params, you can check those out on sklearn website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voted_classifier accuracy:  83.0\n"
     ]
    }
   ],
   "source": [
    "voted_classfier = VoteClassifier(#classifier, \n",
    "                                 MNB_classifier, \n",
    "                                 BNB_classifier,  \n",
    "                                 #SGDClassifier_classifier, \n",
    "                                 LinearSVC_classifier, \n",
    "                                 NuSVC_classifier,\n",
    "                                 LogisticRegression_classifier)\n",
    "print('voted_classifier accuracy: ', nltk.classify.accuracy(voted_classfier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Classfication: \", voted_classfier.classify(test_set[0][0]), \", Confidence: \", voted_classfier.confidence(test_set[0][0]) * 100)\n",
    "# print(\"Classfication: \", voted_classfier.classify(test_set[1][0]), \", Confidence: \", voted_classfier.confidence(test_set[1][0]) * 100)\n",
    "# print(\"Classfication: \", voted_classfier.classify(test_set[2][0]), \", Confidence: \", voted_classfier.confidence(test_set[2][0]) * 100)\n",
    "# print(\"Classfication: \", voted_classfier.classify(test_set[3][0]), \", Confidence: \", voted_classfier.confidence(test_set[3][0]) * 100)\n",
    "# print(\"Classfication: \", voted_classfier.classify(test_set[4][0]), \", Confidence: \", voted_classfier.confidence(test_set[4][0]) * 100)\n",
    "# print(\"Classfication: \", voted_classfier.classify(test_set[5][0]), \", Confidence: \", voted_classfier.confidence(test_set[5][0]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
